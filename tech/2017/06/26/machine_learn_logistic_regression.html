<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>机器学习：逻辑回归</title>
  <meta name="description" content="update: 2017-07-11">

  <link rel="stylesheet" href="../../../../css/main.css">
  <link rel="canonical" href="machine_learn_logistic_regression.html">
  <link rel="alternate" type="application/rss+xml" title="飲冰" href="../../../../feed.xml.rss">

  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-99358515-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-99358515-2');
</script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?93958d5b998cdceacf0dd973dfdf71b5";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

  
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="../../../../index.html">飲冰</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="../../../../about/index.html">简介</a>
          
        
          
        
          
        
          
          <a class="page-link" href="../../../../life/index.html">生活</a>
          
        
          
        
          
          <a class="page-link" href="../../../../misc/index.html">琐碎</a>
          
        
          
          <a class="page-link" href="../../../../recommend.html">推荐</a>
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">机器学习：逻辑回归</h1>
    <p class="post-meta"><time datetime="2017-06-26T00:00:00+00:00" itemprop="datePublished">Jun 26, 2017</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>update: 2017-07-11</p>

<p>逻辑回归在点击率推荐中仍占有半壁江山，于是打算细致做下梳理，包括常见理论变形和工业成熟实现。预计耗时一个月。</p>

<h3 id="0-理论">0. 理论</h3>

<h4 id="01-原理">0.1 原理</h4>

<ul>
  <li><a href="http://nbviewer.jupyter.org/github/facaiy/book_notes/blob/master/machine_learning/logistic_regression/demo.ipynb">逻辑回归算法简介和Python实现</a></li>
</ul>

<h4 id="02-寻优算法">0.2 寻优算法</h4>

<p>常规的机器学习算法，通常有两个过程：一是构建模型，并给出损失函数；二是用数值寻优根据损失函数找到合适参数。</p>

<p>数值寻优本身门类很多，如下面博文所述：</p>

<ul>
  <li><a href="http://www.cnblogs.com/maybe2030/p/4751804.html">常见的几种最优化方法</a></li>
  <li><a href="http://blog.sciencenet.cn/blog-628137-497041.html">学习总结：局部搜索</a></li>
  <li><a href="http://blog.csdn.net/fangqingan_java/article/details/48951191">数值优化（Numerical Optimization）学习系列-目录</a></li>
</ul>

<p>这个领域数理要求很高。不过我个人认为，把它们作为工具看待，了解其特性和区别即可。于是，简要梳理下常见的寻优算子：</p>

<ul>
  <li>最速下降法：用一阶导数做步长搜索。简单，支持导步，但收敛较慢，震荡。
    <ul>
      <li>批量梯度下降法(Batch Gradient Descent, BSD)：全量数据更新。</li>
      <li>随机梯度下降法(Stochastic Gradient Descent, SGD)：数据随机割成多份，逐份更新。</li>
    </ul>
  </li>
  <li>
    <p>牛顿法(Newton-Raphson method)：<a href="http://blog.csdn.net/luoleicn/article/details/6527049">简单介绍</a>，其实质是用二维曲面拟合坐标点，再用曲面的切线进行搜索。优点是利用二阶导信息，收敛更快，缺点需借助Hessian矩阵$O(n^2)$，无法处理大量数据。</p>
  </li>
  <li>拟牛顿法(Quasi-Newton Methods)：用一阶导信息来近似构造Hessian矩阵，简化运算复杂度。
    <ul>
      <li>DFP</li>
      <li>BFGS:
        <ul>
          <li>LBFGS：内存更省。
            <ul>
              <li>WQL-QN: 支持L1正则。</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>共轭梯度法(Conjugate gradient method)：搜索方向由当前梯度和以前搜索方向合成，介于最速下降法与牛顿法之间的一个方法。</li>
</ul>

<p>未来有时间，打算读下经典教材，都是厚部头：</p>

<ul>
  <li>Convex Optimization, Stephen Boyd, Lieven Vandenberghe.</li>
  <li>Numerical Optimization, Jorge Nocedal, Stephen J. Wright.</li>
</ul>

<h3 id="1-工程实现">1. 工程实现</h3>

<ul>
  <li><a href="http://nbviewer.jupyter.org/github/facaiy/book_notes/blob/master/machine_learning/logistic_regression/spark_ml_lr.ipynb">逻辑回归在spark中的实现简介</a></li>
  <li><a href="http://nbviewer.jupyter.org/github/facaiy/book_notes/tree/master/machine_learning/logistic_regression/sklearn_lr.ipynb">逻辑回归在scikit-learn中的实现简介</a></li>
  <li><a href="http://nbviewer.jupyter.org/github/facaiy/book_notes/blob/master/machine_learning/logistic_regression/tensorflow_lr.ipynb">逻辑回归在TensorFlow contrib.learn中的实现简介</a></li>
  <li>Angel</li>
  <li>R pacakge: glm / glmet</li>
  <li>Liblinear</li>
</ul>

<h3 id="2-结语">2. 结语</h3>

<p>逻辑回归的理论既简单又复杂，简单是说二分类的代数式很容易入门看懂，复杂是说对它的拓展可以很深入，如用矩阵式来求解、多分类、复杂的数值优化方法等等。易于入门，难于精通。</p>

<p>虽然线性分类器后面的数理知识坚实又深奥，然而工程实现相对简单，主要是损失函数和导数、及寻优算子二部份。大多数工程实现都大同小异，如sklearn是标签-1/+1的推导，spark在最后代数变换，将0/1标签转成-1/+1，tensorflow是标签0/1的推导。总体而言，代码并不太复杂。</p>

<p>花费了两周时间来梳理基础知识，以后有时间再深入。</p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">飲冰</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li><a href="mailto:facai.yan@gmail.com">facai.yan@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/facaiy"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">facaiy</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>富貴福澤，將厚吾之生也；貧賤憂戚，庸玉女於成也。
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
